{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tifffile as tf\n",
    "from skimage.measure import regionprops\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#custom function\n",
    "from post_analysis import *\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for across channel\n",
    "mtx = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/230608_4k_inv_5bs/pyfish_tools/output/genebycell/final_0.7511.25_seed44_heg_svm_p20.0_diff1_fdr10.0/final/genebycell.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codebook\n",
    "codebook = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/230608_4k_inv_5bs/barcode_key/codebook_string_across.csv\", index_col=0)\n",
    "#separate into true and false codebook\n",
    "fakebook = codebook[codebook.index.str.startswith(\"fake\")]\n",
    "codebook = codebook.drop(fakebook.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate fdr\n",
    "fp, fake = percent_false_positive(mtx, codebook, fakebook)\n",
    "percent_fp = fp[\"FP raw\"].mean()\n",
    "mean_counts = fp[\"total_real\"].mean()\n",
    "sum_counts = fp[\"total_counts\"].sum()\n",
    "norm_fpr = fp[\"FDR\"].mean()\n",
    "fp_list = [percent_fp,norm_fpr,mean_counts,sum_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at fdr results\n",
    "df_stats = pd.DataFrame(fp_list).T\n",
    "df_stats.columns = [\"percent fp\",\"false positive rate\",\"mean true counts\", \"total sum\"]\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency and correlations (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in rnaseq data\n",
    "rnaseq = pd.read_csv(\"./RNAseq_files/NIH3T3_CCS_TPM_REP1.csv\")\n",
    "rnaseq.columns = [\"Genes\",\"TPM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "rnaseq[\"Genes\"] = rnaseq[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_1 = pd.merge(rnaseq,bulk)\n",
    "#pearson's correlation\n",
    "r = pearsonr(comb_1[\"TPM\"],comb_1[\"Counts\"])\n",
    "r = round(r[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get log2 + 1\n",
    "comb_1[\"Log Counts\"] = np.log10(comb_1[\"Counts\"]+0.1)\n",
    "comb_1[\"Log TPM\"] = np.log10(comb_1[\"TPM\"]+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNA-seq plot\n",
    "sns.set_style(\"white\")\n",
    "joint_kws=dict(gridsize=50)\n",
    "hexplot = sns.jointplot(data=comb_1, x=\"Log TPM\", y=\"Log Counts\", kind=\"hex\",mincnt=0.1, \n",
    "              cmap=\"plasma\", dropna=True, joint_kws=joint_kws)\n",
    "plt.xlabel(\"Bulk RNAseq Log10(TPM+0.1)\", fontsize=12)\n",
    "plt.ylabel(\"Pseudobulk Log10(Counts+0.1)\", fontsize=12)\n",
    "hexplot.ax_marg_x.remove()\n",
    "hexplot.ax_marg_y.remove()\n",
    "plt.annotate(f\"Pearson's r= {r}\", (-1.0,0.4), fontsize=12)\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "plt.colorbar()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in smfish and other reference files\n",
    "smfish_density = pd.read_csv(\"./nih3t3_smfish/27gene_smfish_density.csv\", index_col=0)\n",
    "_150genes_density = pd.read_csv(\"./nih3t3_smfish/150_genes_density.csv\", index_col=0)\n",
    "mtx_den = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/230608_4k_inv_5bs/pyfish_tools/output/genebycell/final_0.7511.25_seed33_heg_svm_p20.0_diff1_fdr10.0/final/gene_density_all.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx_den,smfish_density, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=True, \n",
    "            return_comb_df=False, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#150 gene density correlation\n",
    "correlation(mtx_den,_150genes_density, label_x=\"150 genes\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=True, \n",
    "            return_comb_df=False, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average percent decoded\n",
    "percent_decoded_list = []\n",
    "for i in range(52):\n",
    "    for z in range(1):\n",
    "        try:\n",
    "            src = f\"\"\n",
    "            with open(src) as f:\n",
    "                decoded = f.readlines()[0].split(\" \")[-1]\n",
    "                f.close()\n",
    "                percent_decoded_list.append(float(decoded))\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_decoded_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Cell Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import scrublet as scr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as st\n",
    "import gseapy as gp\n",
    "\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Booeshaghi et al,  proportional fitting prior to log transformation followed by an additional proportional fitting is best for normalization (ref 1). \n",
    "\n",
    "ref 1: https://www.biorxiv.org/content/10.1101/2022.05.06.490859v1\n",
    "\n",
    "Another source from Ahlmann-Eltze, says that the logarithm of a pseudo-count followed by principal-component analysis, performs as well or better than the more sophisticated alternatives\n",
    "\n",
    "ref 2: https://www.nature.com/articles/s41592-023-01814-1\n",
    "\n",
    "Do to these reasons, I'm just going to proceed with PFLogPF for normalization instead of sctransform or LogCP10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "import scipy as sp\n",
    "#from ref 1\n",
    "def do_pf(mtx, sf = None):\n",
    "    pf = mtx.sum(axis=1).ravel()\n",
    "    if not sf:\n",
    "        sf = pf.mean()\n",
    "    pf = sp.sparse.diags(sf/pf) @ mtx\n",
    "    return pf\n",
    "\n",
    "def norm_pf_log_pf(mtx):\n",
    "    pf_log_pf = do_pf(np.log1p(do_pf(mtx)))\n",
    "    return pf_log_pf\n",
    "#--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = mtx[~mtx.index.str.startswith(\"fake\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(mtx.T, dtype=mtx.values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This filters cells based on minimal UMI counts. \n",
    "sc.pp.filter_cells(adata, min_counts = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This filters genes based on minimal number of counts\n",
    "sc.pp.filter_genes(adata, min_counts = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(adata.var['n_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = norm_pf_log_pf(adata.X.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.01, max_mean=8,\n",
    "                            min_disp=1, n_top_genes=10, n_bins=20, flavor=\"seurat\")\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean center data and divide by std\n",
    "sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform UMAP\n",
    "sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, n_comps=20)\n",
    "sc.pp.neighbors(adata, n_neighbors=30, n_pcs=20, knn=True)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised clustering with leiden\n",
    "sc.tl.leiden(adata, resolution = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize plot\n",
    "sc.pl.umap(adata, color=\"slc17a7\", title = \"\", show = False)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize plot\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sc.pl.umap(adata, color=\"leiden\", title = \"\", show = False, alpha=0.5)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = pd.read_csv(\"/groups/CaiLab/personal/Lex/raw/230521_10k_human_AD/top25_cluster-markers_2023_0524.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata,'leiden', method='wilcoxon')\n",
    "groups = sc.get.rank_genes_groups_df(adata, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = markers.cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_def = []\n",
    "for uni in range(len(groups.group.unique())):\n",
    "    cls = groups[groups.group == str(uni)]\n",
    "    celltype = []\n",
    "    for cell in types:\n",
    "        genes = markers[markers.cluster == cell].gene.values\n",
    "        genes = [gene.lower() for gene in genes]\n",
    "        overlap = len(set(cls.names.values) & set(genes))\n",
    "        celltype.append([cell, overlap/len(genes)])\n",
    "    celltype = np.array(celltype)\n",
    "    best = np.argmax(celltype[:,1].astype(float))\n",
    "    cluster_def.append([uni, celltype[best]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublet detection (if masks were too big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform scrublet modeling \n",
    "#use unnormalized counts matrix\n",
    "scrub = scr.Scrublet(genes_tpt_live_unnorm.X, expected_doublet_rate = 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate doublet scores\n",
    "doublet_scores, predicted_doublets = scrub.scrub_doublets(min_counts=1, \n",
    "                                                          min_cells=1,\n",
    "                                                          min_gene_variability_pctl=85, \n",
    "                                                          n_prin_comps=50,\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels normalized matrix\n",
    "genes_tpt_live.obs[\"scrublet\"] = predicted_doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color by scrublet doublet\n",
    "sc.pl.umap(genes_tpt_live, color=\"scrublet\", cmap = \"viridis\", show = False)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove doublets\n",
    "genes_tpt_live = genes_tpt_live[genes_tpt_live.obs[\"scrublet\"] == False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
