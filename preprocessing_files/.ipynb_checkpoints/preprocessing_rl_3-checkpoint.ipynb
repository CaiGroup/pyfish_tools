{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that performing a high pass gaussian filter, followed by Richardson-Lucy deconvolution, and low pass gaussian blur best resolves dots. Additionally, it appears to not increase the intensity of \"fake dots\" and really separate nearby dots. This method was adapted from the following reference.\n",
    "\n",
    "1.Moffitt, J. R. et al. High-throughput single-cell gene-expression profiling with multiplexed error-robust fluorescence in situ hybridization. PNAS 113, 11046â€“11051 (2016).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug True automatically gets a test tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "#Switch Directories to import functions\n",
    "#---------------------------------------------\n",
    "old_cwd = os.getcwd()\n",
    "os.chdir('/home/nrezaee/data-pipeline/')\n",
    "#---------------------------------------------\n",
    "\n",
    "\n",
    "#Importing Pipeline Functions\n",
    "#---------------------------------------------\n",
    "from datapipeline_tools.dot_detection.preprocessing.preprocess import blur_back_subtract_3d\n",
    "from datapipeline_tools.dot_detection.preprocessing.preprocess import blur_3d\n",
    "from datapipeline_tools.dot_detection.preprocessing.preprocess import tophat_3d\n",
    "\n",
    "from datapipeline_tools_dev.dot_detection.helpers.background_subtraction import get_shifted_background\n",
    "\n",
    "import load_tiff\n",
    "#---------------------------------------------\n",
    "\n",
    "#Switch Back\n",
    "#---------------------------------------------\n",
    "os.chdir(old_cwd)\n",
    "#---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def plot_2d_image(img_2d, zmax):\n",
    "    \n",
    "    #For Plotting 2d image\n",
    "    #-------------------------------------------\n",
    "    fig = px.imshow(\n",
    "        img_2d,\n",
    "        width=700,\n",
    "        height=700,\n",
    "        binary_string=True,\n",
    "        binary_compression_level=4,\n",
    "        binary_backend='pil',\n",
    "        zmax = zmax\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tiff file Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if debug == True:\n",
    "    \n",
    "#     #Get inputs about tiff src\n",
    "#     #---------------------------------------------\n",
    "#     personal = 'Lex'\n",
    "#     exp_name = '/groups/CaiLab/personal/Lex/raw/20k_dash_063021_3t3/'\n",
    "#     hyb = '0'\n",
    "#     position = '0'\n",
    "#     num_channels = '5'\n",
    "#     #---------------------------------------------\n",
    "\n",
    "#     #Create tiff src\n",
    "#     #---------------------------------------------\n",
    "#     tiff_src = os.path.join('/groups/CaiLab/personal', personal, 'raw', exp_name, 'HybCycle_' + hyb, 'MMStack_Pos' + str(position) + '.ome.tif')\n",
    "#     print(f'{tiff_src=}')\n",
    "#     #---------------------------------------------\n",
    "    \n",
    "    \n",
    "# else:\n",
    "#     #Get inputs about tiff src\n",
    "#     #---------------------------------------------\n",
    "#     personal = input('Personal [nrezaee] : ')\n",
    "#     exp_name = input('Experiment Name [2020-08-08-takei]: ');\n",
    "#     hyb = input('HybCycle [2] : ');\n",
    "#     position = input('Position [0]: ');\n",
    "#     num_channels = input('Number of Channels in tiff [0]: ');\n",
    "#     #---------------------------------------------\n",
    "\n",
    "#     #Create tiff src\n",
    "#     #---------------------------------------------\n",
    "#     tiff_src = os.path.join('/groups/CaiLab/personal', personal, 'raw', exp_name, 'HybCycle_' + hyb, 'MMStack_Pos' + str(position) + '.ome.tif')\n",
    "#     print(f'{tiff_src=}')\n",
    "#     #---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#Import load tiff function from pipeline\n",
    "#---------------------------------------------\n",
    "from datapipeline_tools.load_tiff import tiffy\n",
    "#---------------------------------------------\n",
    "\n",
    "#Load tiff\n",
    "#---------------------------------------------\n",
    "tiff = tiffy.load(\"/groups/CaiLab/personal/Lex/raw/20k_dash_063021_3t3/notebook_pyfiles/aberr_corrected\", \"3\")\n",
    "#---------------------------------------------\n",
    "\n",
    "print(f'{tiff.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff = np.swapaxes(tiff,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Specific Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    ch = 0\n",
    "else:\n",
    "    ch = int(input('Channel to Visualize (Index starting at Zero): '))\n",
    "\n",
    "tiff_3d = tiff[:, ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for plotting tiff 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tiff_3d(tiff_ch, vmax=10, figsize=(10,10), log = True):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        tiff_ch : a 3d tiff channel\n",
    "        vmax : increase to decrease brightness, decrease to increase brightness\n",
    "        figsize : Figure Size\n",
    "        log : Takes log of image for visualization\n",
    "    Outputs:\n",
    "        Plots of 3d image\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make Log of tiff for visualization\n",
    "    #----------------------------------------\n",
    "    if log == True:\n",
    "        tiff_ch = np.log(tiff_ch)\n",
    "    #----------------------------------------\n",
    "    \n",
    "    #Loop through each z \n",
    "    #----------------------------------------\n",
    "    for i in range(len(tiff_ch)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(tiff_ch[i], cmap='gray', vmax=vmax)\n",
    "    #----------------------------------------\n",
    "    \n",
    "#Plot Raw image\n",
    "#----------------------------------------\n",
    "plot_tiff_3d(tiff[:, 0], figsize= (10,10), vmax=8)\n",
    "#----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Subtract the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yn_choice(message, default='y'):\n",
    "    \"\"\"\n",
    "    Makes message and input with a binary choice\n",
    "    \"\"\"\n",
    "    choices = 'Y/n' if default.lower() in ('y', 'yes') else 'y/N'\n",
    "    choice = input(\"%s (%s) \" % (message, choices))\n",
    "    values = ('y', 'yes', '') if choices == 'Y/n' else ('y', 'yes')\n",
    "    return choice.strip().lower() in values\n",
    "\n",
    "if debug:\n",
    "    bool_back_sub = True\n",
    "else:\n",
    "    bool_back_sub = yn_choice('Do you want background subtraction?')\n",
    "    print(f'{bool_back_sub=}')\n",
    "    \n",
    "if bool_back_sub == False:\n",
    "    back_subtracted_3d = tiff_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Shifted Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bool_back_sub == True:\n",
    "    \n",
    "    if debug:\n",
    "        analysis_name = 'lex_align'\n",
    "    else:\n",
    "        analysis_name = input('Analysis Name of Experiment (in order to get offsets): ')\n",
    "\n",
    "    #Get Background\n",
    "    #----------------------------------------\n",
    "    final_background_src = os.path.join('/groups/CaiLab/personal', personal, 'raw', exp_name, 'final_background', 'MMStack_Pos' + str(position) + '.ome.tif')\n",
    "    back_tiff = tiffy.load(final_background_src)\n",
    "    back_ch = back_tiff[:, ch]\n",
    "    #----------------------------------------\n",
    "\n",
    "    #Shift the Background\n",
    "    #----------------------------------------\n",
    "    shifted_back_ch = get_shifted_background(back_ch, tiff_src, analysis_name)\n",
    "    #----------------------------------------\n",
    "    \n",
    "    #Plot Raw image\n",
    "    #----------------------------------------\n",
    "    plot_tiff_3d(back_ch, figsize= (10,10), vmax=7)\n",
    "    #----------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract the Image and plot Raw Image, Background, and Subtracted Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if bool_back_sub == True:\n",
    "    \n",
    "    #Blur Background Beforehand\n",
    "    #----------------------------------------\n",
    "    background_blur_kernel_size = 1\n",
    "    back_ch_blurred = blur_3d(back_ch, background_blur_kernel_size).astype(np.uint16)\n",
    "    #----------------------------------------\n",
    "    \n",
    "    \n",
    "    #Subtracted the image\n",
    "    #----------------------------------------\n",
    "    back_subtracted_3d = cv2.subtract(tiff_3d, back_ch_blurred)\n",
    "    #----------------------------------------\n",
    "    \n",
    "    #plot_tiff_3d(back_subtracted_3d, log = False)\n",
    "\n",
    "    back_check_dir_dst = 'Background_Subtraction_Checks'\n",
    "    os.makedirs(back_check_dir_dst, exist_ok = True)\n",
    "    for i in range(len(tiff_3d)):\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize = (20,20))\n",
    "        axs[0].imshow(np.log(tiff_3d[i]), cmap='gray', vmax= 8)\n",
    "        axs[0].title.set_text('Raw image Z ' + str(i)) \n",
    "\n",
    "        axs[1].imshow(np.log(back_ch_blurred[i]), cmap='gray', vmax = 8)\n",
    "        axs[1].title.set_text('Background image Z ' + str(i)) \n",
    "\n",
    "        axs[2].imshow(back_subtracted_3d[i], cmap='gray', vmax=1200)\n",
    "        axs[2].title.set_text('Back Subtracted image image Z ' + str(i)) \n",
    "\n",
    "        fig_dst = os.path.join(back_check_dir_dst, 'z_' + str(i) + '.png')\n",
    "        fig.savefig(fig_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Background image\n",
    "#----------------------------------------\n",
    "plot_tiff_3d(back_subtracted_3d, figsize= (10,10), vmax=3000, log=False)\n",
    "#----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skimage Rolling ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import color, data, restoration, util\n",
    "# image = []\n",
    "# for i in range(2):\n",
    "#     background = restoration.rolling_ball(back_subtracted_3d[i], radius=5, num_threads=8)\n",
    "#     rb_processed = back_subtracted_3d[i]-background\n",
    "#     image.append(rb_processed)\n",
    "# rb_processed = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_2d_image(rb_processed[0], zmax=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_2d_image(back_subtracted_3d[0], zmax=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High pass mean filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import util\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def high_pass_mean(img, kern=25):\n",
    "    \"\"\"A high pass mean filter\n",
    "    Parameters\n",
    "    ----------\n",
    "    img = z,c,x,y\n",
    "    kern = int\n",
    "    \"\"\"\n",
    "    #generate kernel\n",
    "    kernel = np.ones((kern,kern),np.float32)/kern**2\n",
    "    #blur the image and subtract\n",
    "    z_slice = []\n",
    "    for z in range(img.shape[0]):\n",
    "        channel_slice = []\n",
    "        for c in range(img.shape[1]):\n",
    "            #mean filter\n",
    "            blur = cv2.filter2D(img[z][c],-1,kernel)\n",
    "            #subtract\n",
    "            filtered = util.img_as_int(img[z][c])-util.img_as_int(blur)\n",
    "            #set negative values to zero\n",
    "            filtered[filtered<0]=0\n",
    "            channel_slice.append(filtered)\n",
    "        z_slice.append(channel_slice)\n",
    "    return np.array(z_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpmf_image = high_pass_mean(tiff, kern=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(hpmf_image[1][0], zmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high pass mean filter matches the output of Nick's rolling ball. It should be noted that the definition for rolling ball between ImageJ and skimage is different. ImageJ does a mean blur with a circular selection element. Then it subtracts the blurred image from the real image. Skimage calculates the local minima for a given area using a circular selection element. Then, it subtracts that value from the real image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High pass gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import util\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def high_pass_gaussian(img, kern=9):\n",
    "    \"\"\"A high pass gaussian filter\n",
    "    Parameters\n",
    "    ----------\n",
    "    img = z,c,x,y\n",
    "    kern = int\n",
    "    \"\"\"\n",
    "    #generate kernel\n",
    "    kernel = np.ones((kern,kern),np.float32)/kern**2\n",
    "    #blur the image and subtract\n",
    "    z_slice = []\n",
    "    for z in range(img.shape[0]):\n",
    "        channel_slice = []\n",
    "        for c in range(img.shape[1]):\n",
    "            #gaussian filter\n",
    "            blur = cv2.GaussianBlur(img[z][c],(kern,kern),cv2.BORDER_DEFAULT)\n",
    "            #subtract\n",
    "            filtered = util.img_as_int(img[z][c])-util.img_as_int(blur)\n",
    "            #set negative values to zero\n",
    "            filtered[filtered<0]=0\n",
    "            channel_slice.append(filtered)\n",
    "        z_slice.append(channel_slice)\n",
    "    return np.array(z_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpgb_image = high_pass_gaussian(tiff, kern=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(hpgb_image[1][0], zmax=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution using Richardson-Lucy algorithm: Use after some form of high pass filter to prevent fake dots form becoming real dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, data, restoration, util\n",
    "from tqdm import tqdm\n",
    "\n",
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\"Generates a gaussian kernel where the sum of all values equals 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    size = int\n",
    "    sigma = int\n",
    "    normalize = bool\"\"\"\n",
    "    half = size//2\n",
    "    if size % 2 == 0:\n",
    "        center = half - 0.5\n",
    "    else:\n",
    "        center = half\n",
    "    X, Y = np.mgrid[0:size, 0:size]\n",
    "    exp = (X - center)**2 / (2 * sigma * sigma) + (Y - center)**2 / (2 * sigma * sigma)\n",
    "    kern = (1/(2*np.pi*(sigma**2)))*np.exp(-exp)\n",
    "    \n",
    "    return kern\n",
    "\n",
    "def RL_deconvolution(image, kernel=1, sigma=(1.8,1.6,1.5,1.3), microscope = \"boc\"):\n",
    "    \"\"\"Assuming a gaussian psf, images are deconvoluted using the richardson-lucy algorithm\n",
    "    Parameters\n",
    "    ----------\n",
    "    image = multi or single array of images\n",
    "    kernel = int\n",
    "    sigma = define sigma at each channel (750nm,647nm,555nm,488nm)\n",
    "    microscope = use preset sigmas for defined scope (\"boc\" and \"lb\")\n",
    "    \"\"\"\n",
    "    # defined sigma from testing\n",
    "    sigma_dict = {\"boc\":[1.8,1.6,1.5,1.3],\"lb\":[2.0,1.7,1.3,1.2]}\n",
    "    \n",
    "    #check to see if it is one z\n",
    "    if len(image) == 1:\n",
    "        channel_slice = []\n",
    "        #perform deconvolution on each channel\n",
    "        if microscope == None:\n",
    "            for c in range(image.shape[1]):\n",
    "                psf = gaussian_kernel(kernel, sigma[c])\n",
    "                adj_img = util.img_as_float(image[c]) + 1E-4\n",
    "                deconvolved_RL = restoration.richardson_lucy(adj_img, psf, 20)\n",
    "                channel_slice.append(deconvolved_RL)\n",
    "            return psf, util.img_as_uint(np.array(channel_slice))\n",
    "        else:\n",
    "            ch_sigma = sigma_dict[microscope]\n",
    "            for c in range(image.shape[1]):\n",
    "                psf = gaussian_kernel(kernel, ch_sigma[c])\n",
    "                adj_img = util.img_as_float(image[c]) + 1E-4\n",
    "                deconvolved_RL = restoration.richardson_lucy(adj_img, psf, 20)\n",
    "                channel_slice.append(deconvolved_RL)\n",
    "            return psf, util.img_as_uint(np.array(channel_slice))\n",
    "    \n",
    "    else:\n",
    "        if microscope == None:\n",
    "            z_slice=[] \n",
    "            #go across z's and channels\n",
    "            for z in tqdm(range(image.shape[0])):\n",
    "                channel_slice=[]\n",
    "                #deconvolution\n",
    "                for c in range(image.shape[1]):\n",
    "                    psf = gaussian_kernel(kernel, sigma[c])\n",
    "                    adj_img = util.img_as_float(image[z][c]) + 1E-4\n",
    "                    deconvolved_RL = restoration.richardson_lucy(adj_img, psf, 20)\n",
    "                    channel_slice.append(deconvolved_RL)\n",
    "                z_slice.append(channel_slice)\n",
    "            img_arr = np.array(z_slice)\n",
    "            img_arr = util.img_as_uint(img_arr)\n",
    "            return psf, img_arr\n",
    "        else:\n",
    "            ch_sigma = sigma_dict[microscope]\n",
    "            z_slice=[] \n",
    "            #go across z's and channels\n",
    "            for z in tqdm(range(image.shape[0])):\n",
    "                channel_slice=[]\n",
    "                #deconvolution\n",
    "                for c in range(image.shape[1]):\n",
    "                    psf = gaussian_kernel(kernel, ch_sigma[c])\n",
    "                    adj_img = util.img_as_float(image[z][c]) + 1E-4\n",
    "                    deconvolved_RL = restoration.richardson_lucy(adj_img, psf, 20)\n",
    "                    channel_slice.append(deconvolved_RL)\n",
    "                z_slice.append(channel_slice)\n",
    "            img_arr = np.array(z_slice)\n",
    "            img_arr = util.img_as_uint(img_arr)\n",
    "            return psf, img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good old Lucy\n",
    "psf, rl_img_hpmf = RL_deconvolution(hpmf_image[:,:4,:,:], kernel = 5,\n",
    "                                    sigma=(1.8,1.6,1.5,1.3), microscope = \"lb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good old Lucy\n",
    "psf, rl_img_hpgb = RL_deconvolution(hpgb_image[:,:4,:,:], kernel = 5,\n",
    "                                    sigma=(1.8,1.6,1.5,1.3), microscope = \"lb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #good old Lucy\n",
    "# psf, rl_img_nofilt = RL_deconvolution(back_subtracted_3d, kernel = 5,sigma = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# # Plot the surface.\n",
    "# X = np.arange(0, 10, 1)\n",
    "# Y = np.arange(0,10, 1)\n",
    "# X, Y = np.meshgrid(X, Y)\n",
    "# ax.plot_surface(X, Y, psf, cmap=\"coolwarm\", linewidth=0, antialiased=False)\n",
    "\n",
    "# # rotate the axes and update\n",
    "# for angle in range(40, 360):\n",
    "#     ax.view_init(40, angle)\n",
    "#     plt.draw()\n",
    "#     plt.pause(.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPMF after deconvolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# image = []\n",
    "# kernel = np.ones((25,25),np.float32)/625\n",
    "# #blur the image with 25 pixel kernel\n",
    "# for i in range(2):\n",
    "#     image.append(cv2.filter2D(rl_img_nofilt[i],-1,kernel))\n",
    "# blur_hpmf_aft_rl = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import util\n",
    "# #subtract blurred background from real image\n",
    "# hpmf_aft_rl_image = []\n",
    "# for i in range(len(blur_hpmf_aft_rl)):\n",
    "#     new = util.img_as_int(rl_img_nofilt[i])-util.img_as_int(blur_hpmf_aft_rl[i])\n",
    "#     #make negative values 0\n",
    "#     new[new<0]=0\n",
    "#     hpmf_aft_rl_image.append(new)\n",
    "# hpmf_aft_rl_image = np.array(hpmf_aft_rl_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_2d_image(hpmf_aft_rl_image[0], zmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all before low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(rl_img_hpmf[0][1], zmax=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(rl_img_hpgb[0][1], zmax=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(tiff[0][1], zmax=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_2d_image(rl_img_nofilt[0], zmax=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_2d_image(hpmf_aft_rl_image[0], zmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_gaussian(image, kern=3):\n",
    "    \"\"\"A low pass gaussian blur\n",
    "    Parameters\n",
    "    ----------\n",
    "    image = single or list of arrays\n",
    "    kern = int\n",
    "    \"\"\"\n",
    "    z_slice = []\n",
    "    for z in range(image.shape[0]):\n",
    "        channel_slice = []\n",
    "        for c in range(image.shape[1]):\n",
    "            channel_slice.append(cv2.GaussianBlur(image[z][c],(kern,kern),cv2.BORDER_DEFAULT))\n",
    "        z_slice.append(channel_slice)\n",
    "    return np.array(z_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpgf\n",
    "rl_img_lpmf = low_pass_gaussian(rl_img_hpmf, kern = 3)\n",
    "rl_img_lpgb = low_pass_gaussian(rl_img_hpgb, kern = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(rl_img_lpmf[0][1], zmax=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(rl_img_lpgb[0][2], zmax=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_image(tiff[0][2], zmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.blur** is used on each z slice.\n",
    "\n",
    "Supplemental Information:\n",
    "https://www.geeksforgeeks.org/python-opencv-cv2-blur-method/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur_kernel_size = 1\n",
    "\n",
    "# #Blur image 3d \n",
    "# #----------------------------------------\n",
    "# blurred_3d = blur_3d(back_subtracted_3d, blur_kernel_size)\n",
    "# #----------------------------------------\n",
    "\n",
    "# #Plot Blurred image\n",
    "# #----------------------------------------\n",
    "# plot_tiff_3d(blurred_3d, figsize= (10,10), vmax=1500, log=False)\n",
    "# #----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tophat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.tophat** is used on each z slice.\n",
    "\n",
    "Supplemental information:\n",
    "\n",
    "https://www.geeksforgeeks.org/top-hat-and-black-hat-transform-using-python-opencv/\n",
    "https://theailearner.com/tag/top-hat-transform-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tophat_kernel_size = 6\n",
    "\n",
    "\n",
    "# #Tophat 3d\n",
    "# #----------------------------------------\n",
    "# tophatted_3d = tophat_3d(rolling_ball_3d, tophat_kernel_size)\n",
    "# #----------------------------------------\n",
    "\n",
    "# #Plot tiff 3d\n",
    "# #----------------------------------------\n",
    "# plot_tiff_3d(tophatted_3d, figsize= (10,10), vmax=1000, log= False)\n",
    "# #----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cai Lab common)",
   "language": "python",
   "name": "python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
