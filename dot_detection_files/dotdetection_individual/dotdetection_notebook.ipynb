{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot detection using DAOStarFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function\n",
    "from daostarfinder_dotdetection import *\n",
    "from util import pil_imread\n",
    "#enhance figure display\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def plot_2d_locs_on_2d_image(df_locs_2d_1, df_locs_2d_2, img_2d,add_trace = True, zmax=1000):\n",
    "    \n",
    "    #For Plotting 2d image\n",
    "    #-------------------------------------------\n",
    "    fig = px.imshow(\n",
    "        img_2d,\n",
    "        width=700,\n",
    "        height=700,\n",
    "        binary_string=True,\n",
    "        binary_compression_level=4,\n",
    "        binary_backend='pil',\n",
    "        zmax = zmax\n",
    "    )\n",
    "    #-------------------------------------------\n",
    "    \n",
    "    #For Plotting 2d dots\n",
    "    #-------------------------------------------\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=df_locs_2d_1.x,\n",
    "        y=df_locs_2d_1.y,\n",
    "        mode='markers',\n",
    "        marker_symbol='cross',\n",
    "        marker=dict(\n",
    "            #maxdisplayed=1000,\n",
    "            size=4\n",
    "            ),\n",
    "        name = \"Gaussian\"\n",
    "        )\n",
    "    )\n",
    "    if add_trace == True:\n",
    "        fig.add_trace(go.Scattergl(\n",
    "            x=df_locs_2d_2.x,\n",
    "            y=df_locs_2d_2.y,\n",
    "            mode='markers',\n",
    "            marker_symbol='cross',\n",
    "            marker=dict(\n",
    "                #maxdisplayed=1000,\n",
    "                size=4\n",
    "                ),\n",
    "            name = \"LoG\"\n",
    "            )\n",
    "        )\n",
    "    #-------------------------------------------\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "def plot_3d_locs_on_2d_image(df_tiff_1, df_tiff_2, tiff, channel, \n",
    "                             raw_src = None, raw_image = False, add_trace = True, zmax=10):\n",
    "    \n",
    "    if raw_image == False:\n",
    "\n",
    "        #PLot All Z's that had dot detection\n",
    "        #-------------------------------------------\n",
    "        for z in range(len(tiff[:,channel-1])):\n",
    "            if add_trace == False:\n",
    "                df_locs_2d_1 = df_tiff_1[(df_tiff_1.z > z-1) & (df_tiff_1.z < z+1)]\n",
    "                plot_2d_locs_on_2d_image(df_locs_2d_1, None, tiff[z, channel-1], zmax=zmax, add_trace=add_trace)\n",
    "            else:\n",
    "                df_locs_2d_1 = df_tiff_1[(df_tiff_1.z > z-1) & (df_tiff_1.z < z+1)]\n",
    "                df_locs_2d_2= df_tiff_2[(df_tiff_2.z > z-1) & (df_tiff_2.z < z+1)]\n",
    "                plot_2d_locs_on_2d_image(df_locs_2d_1,df_locs_2d_2, tiff[z, channel-1],add_trace=add_trace, zmax=zmax)\n",
    "    else:\n",
    "        #read raw image\n",
    "        tiff = tf.imread(raw_src)\n",
    "        if len(tiff.shape) == 3:\n",
    "            tiff = tiff.reshape(1,tiff.shape[0],tiff.shape[1],tiff.shape[2])\n",
    "        print(\"shape =\", tiff.shape)\n",
    "        #plot\n",
    "        for z in range(len(tiff[:,channel-1])):\n",
    "            if add_trace == False:\n",
    "                df_locs_2d_1 = df_tiff_1[(df_tiff_1.z > z-1) & (df_tiff_1.z < z+1)]\n",
    "                plot_2d_locs_on_2d_image(df_locs_2d_1,None, tiff[z, channel-1], zmax=zmax, add_trace=add_trace)\n",
    "            else:\n",
    "                df_locs_2d_1 = df_tiff_1[(df_tiff_1.z > z-1) & (df_tiff_1.z < z+1)]\n",
    "                df_locs_2d_2= df_tiff_2[(df_tiff_2.z > z-1) & (df_tiff_2.z < z+1)]\n",
    "                plot_2d_locs_on_2d_image(df_locs_2d_1,df_locs_2d_2, tiff[z, channel-1],add_trace=add_trace, zmax=zmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#start time\n",
    "start = time.time()\n",
    "hyb = 0\n",
    "pos = 0\n",
    "#image sources\n",
    "img_src = f\"/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/pre_processed_images/HybCycle_{hyb}/MMStack_Pos{pos}.ome.tif\"\n",
    "img_raw = f'/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/dapi_aligned/fiducial_aligned/HybCycle_{hyb}/MMStack_Pos{pos}.ome.tif'\n",
    "raw_src=None\n",
    "\n",
    "#img_src: path to image\n",
    "#HybCycle: which hybcycle are we looking at\n",
    "#size_cutoff: number of standard deviation away from mean size area\n",
    "#threshold: absolute pixel intensity the spot must be greater than\n",
    "#channel: which channel you want to analyze\n",
    "\n",
    "dots = dot_detection(img_src, HybCycle=hyb, size_cutoff=4, threshold=0.01,channel=1, swapaxes=False)\n",
    "print(f\"This task took {(time.time() - start)/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dots on top of image\n",
    "plot_3d_locs_on_2d_image(dots,None, tiff=None, channel=1, raw_src = img_raw, \n",
    "                         raw_image = True, add_trace=False, zmax=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dots on top of image\n",
    "tiff = pil_imread(img_src, swapaxes=True)\n",
    "plot_3d_locs_on_2d_image(dots,None, tiff=tiff, channel=1, raw_src = None, \n",
    "                         raw_image = False, add_trace=False, zmax=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick colocalization check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For colocalization betweenn 1st and last hyb. Use the \"hyb_coloc\" scripts in colocalization_files. The necessary batch files are there for analyzing multiple channels and pos in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if there are weird dropouts in a certain hyb for each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect arrays\n",
    "channel = 4\n",
    "comb_dots_list = []\n",
    "for i in range(11):\n",
    "    path = f\"/groups/CaiLab/personal/Lex/raw/020422_20kdash_3t3/notebook_pyfiles/dots_comb/Channel_{channel}/MMStack_Pos0/Threshold_{i}/Dot_Locations/locations_z_0.csv\"\n",
    "    arr1  = pd.read_csv(path)\n",
    "    comb_dots_list.append(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts total number of dots across hybs\n",
    "final_counts = []\n",
    "for df in comb_dots_list:\n",
    "    dots_per_hyb = []\n",
    "    for i in df[\"hyb\"].unique():\n",
    "        dots_per_hyb.append(len(df[df[\"hyb\"]==i]))\n",
    "    final_counts.append(dots_per_hyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate subplot canvas\n",
    "x = 4\n",
    "fig, ax = plt.subplots(x, x, figsize=(8,10), sharex = True, constrained_layout=True)\n",
    "fig.text(0.5, 0.2, 'HybCycles', ha='center')\n",
    "fig.text(-0.03, 0.6, 'Total Counts', va='center', rotation='vertical')\n",
    "i = 0\n",
    "\n",
    "#fill subplots\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        try:\n",
    "            #generate scatter plot of gene\n",
    "            col.bar(x=np.arange(1,len(final_counts[i])+1,1) ,height=final_counts[i])\n",
    "            sns.despine()\n",
    "            col.set_title(f\"Threshold {i}\")\n",
    "        except IndexError:\n",
    "            col.remove()\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine threshold channels (for dash or across channel data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define channels used\n",
    "channel = [1,2,3,4]\n",
    "#define number of z's\n",
    "num_z = 1\n",
    "#define number of thresholds\n",
    "num_thresholds = 11\n",
    "#for each channel in a specific threshold, grab the locations file\n",
    "#then, concatenate those files and write it out\n",
    "for i in range(num_thresholds):\n",
    "    for z in range(num_z):\n",
    "        thresh_df = []\n",
    "        for c in channel:\n",
    "            paths = f\"/groups/CaiLab/personal/Lex/raw/020422_20kdash_3t3/notebook_pyfiles/dots_comb/Channel_{c}/MMStack_Pos0/Threshold_{i}/Dot_Locations/locations_z_{z}.csv\"\n",
    "            df = pd.read_csv(paths)\n",
    "            thresh_df.append(df)\n",
    "        df_comb = pd.concat(thresh_df).reset_index(drop=True)\n",
    "        output= Path(f\"/groups/CaiLab/personal/Lex/raw/020422_20kdash_3t3/notebook_pyfiles/dots_comb/channels_combined/Threshold_{i}\")\n",
    "        output.mkdir(parents=True,exist_ok=True)\n",
    "        output = output / f\"locations_z_{z}.csv\"\n",
    "        df_comb.to_csv(str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../dots_comb/channels_combined/Threshold_0/locations_z_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df[\"hyb\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine channels for all pos (after picking best set) if you encoded across channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#define channels used\n",
    "channel = [1,2,3,4]\n",
    "#define total number of pos\n",
    "pos_tot = 107\n",
    "#define number of z's\n",
    "num_z = 2\n",
    "#define number of thresholds\n",
    "num_thresholds = 11\n",
    "#for each channel in a specific position, grab the locations file\n",
    "#then, concatenate those files and write it out\n",
    "for i in tqdm(range(pos_tot)):\n",
    "    for z in range(num_z):\n",
    "        df_list = []\n",
    "        for c in channel:\n",
    "            paths = f\"/groups/CaiLab/personal/Lex/raw/112221_20kdash_3t3/notebook_pyfiles/dots_comb/final/Channel_{c}/MMStack_Pos{i}/locations_z_{z}.csv\"\n",
    "            df = pd.read_csv(paths)\n",
    "            df_list.append(df)\n",
    "        df_comb = pd.concat(df_list).reset_index(drop=True)\n",
    "        output= Path(f\"/groups/CaiLab/personal/Lex/raw/112221_20kdash_3t3/notebook_pyfiles/dots_comb/final/channels_combined_daostar/MMStack_Pos{i}\")\n",
    "        output.mkdir(parents=True,exist_ok=True)\n",
    "        output = output / f\"locations_z_{z}.csv\"\n",
    "        df_comb.to_csv(str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../dots_comb/final/channels_combined_daostar/MMStack_Pos0/locations_z_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hyb\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
