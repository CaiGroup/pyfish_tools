{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "#custom function\n",
    "from false_positive_analysis import percent_false_positive\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in final mtx\n",
    "#grab all channels\n",
    "all_channels = []\n",
    "\n",
    "for c in [1]:\n",
    "    mtx = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/genebycell/final_11p52_33_heg_svm_0p10_diff0_fdr10/final/genebycell_{c}.csv\", index_col=0)\n",
    "    mtx = mtx.T\n",
    "    mtx = mtx[mtx.sum(axis=1)>100].T\n",
    "    all_channels.append(mtx)\n",
    "\n",
    "mtx = pd.concat(all_channels, axis=0).fillna(0)\n",
    "#mtx = mtx.T\n",
    "#mtx = mtx[mtx.sum(axis=1)>300].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in rnaseq data\n",
    "rnaseq = pd.read_csv(\"./RNAseq_files/NIH3T3_CCS_TPM_REP1.csv\")\n",
    "rnaseq.columns = [\"Genes\",\"TPM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codebook\n",
    "codebooks = [\"codebook_string_647.csv\",\"codebook_string_561.csv\",\"codebook_string_488.csv\"]\n",
    "codebook = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/decoding_files/SVM_Feature_Radial_Decoding/codebook_converter/{codebooks[c-1]}\", index_col=0)\n",
    "#separate into true and false codebook\n",
    "fakebook = codebook[codebook.index.str.startswith(\"fake\")]\n",
    "codebook = codebook.drop(fakebook.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate fdr\n",
    "fp, fake = percent_false_positive(mtx, codebook, fakebook)\n",
    "percent_fp = fp[\"FP raw\"].mean()\n",
    "mean_counts = fp[\"total_real\"].mean()\n",
    "sum_counts = fp[\"total_counts\"].sum()\n",
    "norm_fpr = fp[\"FDR\"].mean()\n",
    "fp_list = [percent_fp,norm_fpr,mean_counts,sum_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at fdr results\n",
    "df_stats = pd.DataFrame(fp_list).T\n",
    "df_stats.columns = [\"percent fp\",\"false positive rate\",\"mean true counts\", \"total sum\"]\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "rnaseq[\"Genes\"] = rnaseq[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_1 = pd.merge(rnaseq,bulk)\n",
    "#pearson's correlation\n",
    "r = pearsonr(comb_1[\"TPM\"],comb_1[\"Counts\"])\n",
    "r = round(r[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get log2 + 1\n",
    "comb_1[\"Log Counts\"] = np.log10(comb_1[\"Counts\"]+0.1)\n",
    "comb_1[\"Log TPM\"] = np.log10(comb_1[\"TPM\"]+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNA-seq plot\n",
    "sns.set_style(\"white\")\n",
    "joint_kws=dict(gridsize=50)\n",
    "hexplot = sns.jointplot(data=comb_1, x=\"Log TPM\", y=\"Log Counts\", kind=\"hex\",mincnt=0.1, \n",
    "              cmap=\"plasma\", dropna=True, joint_kws=joint_kws)\n",
    "plt.xlabel(\"Bulk RNAseq Log10(TPM+0.1)\", fontsize=12)\n",
    "plt.ylabel(\"Pseudobulk Log10(Counts+0.1)\", fontsize=12)\n",
    "hexplot.ax_marg_x.remove()\n",
    "hexplot.ax_marg_y.remove()\n",
    "plt.annotate(f\"Pearson's r= {r}\", (-0.8,1.2), fontsize=12)\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "plt.colorbar()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in smfish \n",
    "smfish = pd.read_csv(\"./nih3t3_smfish/smFISH_results.csv\").T\n",
    "#smfish = pd.read_csv(\"./nih3t3_smfish/smfish_27gene_custom_thresh_2.csv\", index_col=0)\n",
    "_150genes = pd.read_csv(\"./150genes_diff0.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pseudobulk results \n",
    "smfish_df = pd.DataFrame(smfish.mean(axis=1))\n",
    "smfish_df = smfish_df.reset_index()\n",
    "smfish_df.columns = [\"Genes\", \"smFISH Counts\"]\n",
    "smfish_df[\"Genes\"] = smfish_df[\"Genes\"].str.lower()\n",
    "\n",
    "_150genes = pd.DataFrame(_150genes.mean(axis=1))\n",
    "_150genes = _150genes.reset_index()\n",
    "_150genes.columns = [\"Genes\", \"150 genes\"]\n",
    "_150genes[\"Genes\"] = _150genes[\"Genes\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_2 = pd.merge(smfish_df,bulk)\n",
    "#calculate info\n",
    "x = comb_2[\"smFISH Counts\"].values\n",
    "x_t = np.vstack([x, np.zeros(len(x))]).T\n",
    "y = comb_2[\"Counts\"].values\n",
    "m,c = np.linalg.lstsq(x_t, y, rcond=None)[0]\n",
    "r = pearsonr(x,y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4,5), dpi=80)\n",
    "#show smfish correlation\n",
    "plt.plot(x, y, 'bo', alpha=0.5)\n",
    "plt.plot(x, x*m, c = \"k\")\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "plt.xlabel(\"Average smFISH counts\")\n",
    "plt.ylabel(\"Average LANTERN Counts\")\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (0,16), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (0,15), fontsize=12)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4,5), dpi=80)\n",
    "#plot correlation and efficiency\n",
    "plt.scatter(x = np.log2(comb_2[\"smFISH Counts\"]), y = np.log2(comb_2[\"Counts\"]), c=\"b\", alpha=0.5)\n",
    "plt.xlabel(\"Log2(Average smFISH Counts)\", fontsize=12)\n",
    "plt.ylabel(\"Log2(Average LANTERN Counts)\", fontsize=12)\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (-1.2,4.2), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (-1.2,3.7), fontsize=12)\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_2 = pd.merge(_150genes,bulk)\n",
    "comb_2 = comb_2.drop(comb_2[comb_2[\"Genes\"].str.startswith(\"fake\")].index)\n",
    "#calculate info\n",
    "x = comb_2[\"150 genes\"].values\n",
    "x_t = np.vstack([x, np.zeros(len(x))]).T\n",
    "y = comb_2[\"Counts\"].values\n",
    "m,c = np.linalg.lstsq(x_t, y, rcond=None)[0]\n",
    "r = pearsonr(x,y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4,5), dpi=80)\n",
    "#show smfish correlation\n",
    "plt.plot(x, y, 'bo', alpha=0.5)\n",
    "plt.plot(x, x*m, c = \"k\")\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "plt.xlabel(\"Average 150 gene LANTERN counts\")\n",
    "plt.ylabel(\"Average LANTERN Counts\")\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (0,16), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (0,15), fontsize=12)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4,5), dpi=80)\n",
    "#plot correlation and efficiency\n",
    "plt.scatter(x = np.log2(comb_2[\"150 genes\"]), y = np.log2(comb_2[\"Counts\"]), c=\"b\", alpha=0.5)\n",
    "plt.xlabel(\"Log2(Average 150 gene LANTERN Counts)\", fontsize=12)\n",
    "plt.ylabel(\"Log2(Average LANTERN Counts)\", fontsize=12)\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (-5,4.2), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (-5,3.6), fontsize=12)\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average percent decoded\n",
    "percent_decoded_list = []\n",
    "for i in range(52):\n",
    "    for z in range(1):\n",
    "        try:\n",
    "            src = f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p10_diff0_fdr10_seed2/Channel_3/Pos_{i}/percent_decoded_z_{z}.txt\"\n",
    "            with open(src) as f:\n",
    "                decoded = f.readlines()[0].split(\" \")[-1]\n",
    "                f.close()\n",
    "                percent_decoded_list.append(float(decoded))\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_decoded_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check spot count diff\n",
    "fold_diff = []\n",
    "channel = 2\n",
    "for i in range(25):\n",
    "    current = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    current = current[current[\"hyb\"] < 12]\n",
    "    old = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/1000genes_040222/notebook_pyfiles/dots_detected/Channel_1_preprocessed/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    old = old[old[\"hyb\"] <11]\n",
    "\n",
    "    old_counts_cell = np.mean(old.groupby(\"cell number\").size())\n",
    "    current_counts_cell = np.mean(current.groupby(\"cell number\").size())\n",
    "    \n",
    "    fold = current_counts_cell/old_counts_cell\n",
    "    \n",
    "    fold_diff.append(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fold_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_und_list = []\n",
    "channel=3\n",
    "for i in range(25):\n",
    "    current_und = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p10_diff0_fdr10/Channel_{channel}/Pos_{i}/dots_used_undefined_z_0.csv\")\n",
    "    current_und = current_und[current_und[\"hyb\"] < 48]\n",
    "    current_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    current_loc = current_loc[current_loc[\"hyb\"] < 48]\n",
    "    current_per = len(current_und)/len(current_loc)\n",
    "    \n",
    "    old_und = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p10_diff0_fdr10/Channel_{channel}/Pos_{i}/dots_used_undefined_z_0.csv\")\n",
    "    old_und = old_und[old_und[\"hyb\"] <48]\n",
    "    old_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    old_loc = old_loc[old_loc[\"hyb\"] <48]\n",
    "    old_per = len(old_und)/len(old_loc)\n",
    "    \n",
    "    diff = old_per - current_per\n",
    "    \n",
    "    percent_und_list.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_und_list)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_fake_list = []\n",
    "channel=3\n",
    "for i in range(25):\n",
    "    current_fake = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p10_diff0_fdr10/Channel_{channel}/Pos_{i}/dots_used_fakes_z_0.csv\")\n",
    "    current_fake = current_fake[current_fake[\"hyb\"] < 48]\n",
    "    current_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/060322_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    current_loc = current_loc[current_loc[\"hyb\"] < 48]\n",
    "    current_per = len(current_fake)/len(current_loc)\n",
    "    \n",
    "    old_fake = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p10_diff0_fdr10/Channel_{channel}/Pos_{i}/dots_used_fakes_z_0.csv\")\n",
    "    old_fake = old_fake[old_fake[\"hyb\"] <48]\n",
    "    old_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/052922_4kgene/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    old_loc = old_loc[old_loc[\"hyb\"] <48]\n",
    "    old_per = len(old_fake)/len(old_loc)\n",
    "    \n",
    "    diff = old_per - current_per\n",
    "    \n",
    "    percent_fake_list.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_fake_list)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify problematic hybs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse into gene counts\n",
    "counts_df = Counter(fake[\"genes\"])\n",
    "#change to df\n",
    "counts_df = pd.DataFrame.from_dict(counts_df, orient='index').reset_index()\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check codebook\n",
    "codebook = pd.read_csv(\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/barcode_key/codebook_647nm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase gene names\n",
    "codebook.index = codebook.index.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top 30\n",
    "maj_fakes = counts_df.sort_values(0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get troubled hybs\n",
    "troubled_hybs = []\n",
    "for fakes in maj_fakes[\"index\"]:\n",
    "    troubled_hybs.append(codebook.loc[fakes].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "hybstocheck = np.array(troubled_hybs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "hybstocheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mode for each round\n",
    "bad_hybs = []\n",
    "for i in range(len(hybstocheck[0])):\n",
    "    vals,counts = np.unique(hybstocheck[:,i], return_counts=True)\n",
    "    index = np.argmax(counts)\n",
    "    bad_hyb = vals[index]\n",
    "    bad_hybs.append(bad_hyb)\n",
    "\n",
    "print(f\"Following hybs by rounds are problematic:{bad_hybs}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
