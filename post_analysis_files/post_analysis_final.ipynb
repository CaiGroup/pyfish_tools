{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tifffile as tf\n",
    "from skimage.measure import regionprops\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#custom function\n",
    "from post_analysis import *\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in final mtx\n",
    "#grab all channels\n",
    "all_channels = []\n",
    "\n",
    "for c in [1,2,3]:\n",
    "    mtx = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/genebycell/final_222_33_heg_svm_0p15_diff1_fdr10/final/genebycell_{c}.csv\", index_col=0)\n",
    "    #mtx = mtx.T\n",
    "    #mtx = mtx[mtx.sum(axis=1)>100].T\n",
    "    all_channels.append(mtx)\n",
    "\n",
    "mtx = pd.concat(all_channels, axis=0).fillna(0)\n",
    "mtx = mtx.T\n",
    "mtx = mtx[mtx.sum(axis=1)>300].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in rnaseq data\n",
    "rnaseq = pd.read_csv(\"./RNAseq_files/NIH3T3_CCS_TPM_REP1.csv\")\n",
    "rnaseq.columns = [\"Genes\",\"TPM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codebook\n",
    "codebooks = [\"codebook_string_647.csv\",\"codebook_string_561.csv\",\"codebook_string_488.csv\"]\n",
    "codebook = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoding_files/SVM_Feature_Radial_Decoding/codebook_converter/{codebooks[c-1]}\", index_col=0)\n",
    "#separate into true and false codebook\n",
    "fakebook = codebook[codebook.index.str.startswith(\"fake\")]\n",
    "codebook = codebook.drop(fakebook.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate fdr\n",
    "fp, fake = percent_false_positive(mtx, codebook, fakebook)\n",
    "percent_fp = fp[\"FP raw\"].mean()\n",
    "mean_counts = fp[\"total_real\"].mean()\n",
    "sum_counts = fp[\"total_counts\"].sum()\n",
    "norm_fpr = fp[\"FDR\"].mean()\n",
    "fp_list = [percent_fp,norm_fpr,mean_counts,sum_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at fdr results\n",
    "df_stats = pd.DataFrame(fp_list).T\n",
    "df_stats.columns = [\"percent fp\",\"false positive rate\",\"mean true counts\", \"total sum\"]\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "rnaseq[\"Genes\"] = rnaseq[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_1 = pd.merge(rnaseq,bulk)\n",
    "#pearson's correlation\n",
    "r = pearsonr(comb_1[\"TPM\"],comb_1[\"Counts\"])\n",
    "r = round(r[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get log2 + 1\n",
    "comb_1[\"Log Counts\"] = np.log10(comb_1[\"Counts\"]+0.1)\n",
    "comb_1[\"Log TPM\"] = np.log10(comb_1[\"TPM\"]+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNA-seq plot\n",
    "sns.set_style(\"white\")\n",
    "joint_kws=dict(gridsize=50)\n",
    "hexplot = sns.jointplot(data=comb_1, x=\"Log TPM\", y=\"Log Counts\", kind=\"hex\",mincnt=0.1, \n",
    "              cmap=\"plasma\", dropna=True, joint_kws=joint_kws)\n",
    "plt.xlabel(\"Bulk RNAseq Log10(TPM+0.1)\", fontsize=12)\n",
    "plt.ylabel(\"Pseudobulk Log10(Counts+0.1)\", fontsize=12)\n",
    "hexplot.ax_marg_x.remove()\n",
    "hexplot.ax_marg_y.remove()\n",
    "plt.annotate(f\"Pearson's r= {r}\", (-1.0,1.6), fontsize=12)\n",
    "plt.title(\"All Channels\", fontweight=\"bold\")\n",
    "plt.colorbar()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in smfish \n",
    "#smfish = pd.read_csv(\"./nih3t3_smfish/smFISH_results.csv\").T\n",
    "smfish = pd.read_csv(\"./nih3t3_smfish/smfish_27gene_custom_thresh_2.csv\", index_col=0)\n",
    "_150genes = pd.read_csv(\"./150genes_diff0.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx,smfish, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=False, \n",
    "            return_comb_df=False, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx,smfish, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=False, \n",
    "            return_comb_df=False, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx,_150genes, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=False, \n",
    "            return_comb_df=False, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx,_150genes, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=False, \n",
    "            return_comb_df=False, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average percent decoded\n",
    "percent_decoded_list = []\n",
    "for i in range(52):\n",
    "    for z in range(1):\n",
    "        try:\n",
    "            src = f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_222_33_heg_svm_0p15_diff1_fdr10/Channel_3/Pos_{i}/percent_decoded_z_{z}.txt\"\n",
    "            with open(src) as f:\n",
    "                decoded = f.readlines()[0].split(\" \")[-1]\n",
    "                f.close()\n",
    "                percent_decoded_list.append(float(decoded))\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_decoded_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_density(locations, mask, pos=0, counts_threshold = 100, density = \"gene\", pixel=0.1):\n",
    "    \n",
    "    \"\"\"Function to return gene or spot density\"\"\"\n",
    "    if density == \"spot\":\n",
    "        area_per_cell = []\n",
    "        info = regionprops(mask)\n",
    "        for cell in info:\n",
    "            area = cell.area\n",
    "            label = cell.label\n",
    "            area_per_cell.append([label,area])\n",
    "\n",
    "        df = pd.DataFrame(area_per_cell)\n",
    "        df.columns = [\"cell number\",\"area\"]\n",
    "\n",
    "        df_loc = pd.DataFrame(locations.groupby(\"cell number\").size()).reset_index()\n",
    "        df_loc.columns = [\"cell number\", \"counts\"]\n",
    "\n",
    "        df_final = pd.merge(df_loc,df)\n",
    "\n",
    "        gene_density = (df_final.counts/df_final.area).values\n",
    "        \n",
    "    else:\n",
    "        area_per_cell = []\n",
    "        info = regionprops(mask)\n",
    "        for cell in info:\n",
    "            area = cell.area\n",
    "            label = cell.label\n",
    "            area_per_cell.append([label,area])\n",
    "\n",
    "        df = pd.DataFrame(area_per_cell)\n",
    "        df.columns = [\"cell number\",\"area\"]\n",
    "        \n",
    "        gene_density = pd.DataFrame()\n",
    "        for cell in locations[\"cell number\"].unique():\n",
    "            gene_counts = locations[locations[\"cell number\"]==cell].groupby(\"genes\").size()\n",
    "            if gene_counts.sum() < counts_threshold:\n",
    "                continue\n",
    "            gene_counts = gene_counts / df[df[\"cell number\"] == cell].area.iloc[0]\n",
    "            gene_counts = gene_counts/(pixel**2)\n",
    "            final_counts = pd.DataFrame(gene_counts)\n",
    "            gene_density[f\"cell{cell}_pos{pos}\"] = gene_counts\n",
    "        gene_density = gene_density.fillna(0)\n",
    "        \n",
    "    \n",
    "    return gene_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 3\n",
    "pixel = 0.1\n",
    "current_df = []\n",
    "ref_df = []\n",
    "for i in range(74):\n",
    "    try:\n",
    "        current = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_222_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/diff_1_minseed_3_z_0_finalgenes.csv\")\n",
    "        #get cell masks\n",
    "        mask = tf.imread(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/edges_deleted/MMStack_Pos{i}_z0.tif\")\n",
    "        current_den = calc_density(current, mask, pos=i, counts_threshold = 100, density = \"gene\", pixel=pixel)\n",
    "        current_df.append(current_den)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "current_df = pd.concat(current_df,axis=1).fillna(0)\n",
    "\n",
    "for i in range(64):\n",
    "    try:\n",
    "        ref = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/050222_150genes4binding/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p15_diff0_newdecoder2/Channel_1/Pos_{i}/diff_0_minseed_3_z_0_finalgenes.csv\")\n",
    "        mask = tf.imread(f\"/groups/CaiLab/personal/Lex/raw/050222_150genes4binding/notebook_pyfiles/edges_deleted/MMStack_Pos{i}.tif\")\n",
    "        ref_den = calc_density(ref, mask, pos=i, counts_threshold = 100, density = \"gene\", pixel=pixel)\n",
    "        ref_df.append(ref_den)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "ref_df = pd.concat(ref_df,axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(current_df,ref_df, label_x=\"150 gene LANTERN\", label_y=\"LANTERN\",\n",
    "            title=\"All Channels\", cell_size_normalized=True, \n",
    "            return_comb_df=False, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 3\n",
    "pixel = 0.1\n",
    "current_df = []\n",
    "for i in range(74):\n",
    "    try:\n",
    "        current = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_222_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/diff_1_minseed_3_z_0_finalgenes.csv\")\n",
    "        #get cell masks\n",
    "        mask = tf.imread(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/edges_deleted/MMStack_Pos{i}_z0.tif\")\n",
    "        current_den = calc_density(current, mask, pos=i, counts_threshold = 100, density = \"gene\", pixel=pixel)\n",
    "        current_df.append(current_den)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "#alter smfish genebycell\n",
    "genebycell = pd.read_csv(\"./nih3t3_smfish/smfish_27gene_custom_thresh_2.csv\", index_col=0)\n",
    "\n",
    "area_smfish = []\n",
    "for i in range(31):\n",
    "    mask = tf.imread(f\"/groups/CaiLab/personal/Lex/raw/042022_40genes_smfish/notebook_pyfiles/edges_deleted/MMStack_Pos{i}.tif\")\n",
    "    area_per_cell = []\n",
    "    info = regionprops(mask)\n",
    "    for cell in info:\n",
    "        area = cell.area\n",
    "        label = cell.label\n",
    "        area_per_cell.append([label,area])\n",
    "\n",
    "    df = pd.DataFrame(area_per_cell)\n",
    "    df.columns = [\"cell number\",\"area\"]\n",
    "    df[\"pos\"]=i\n",
    "    area_smfish.append(df)\n",
    "area_smfish = pd.concat(area_smfish)\n",
    "\n",
    "#get density for each column\n",
    "for cell_id in genebycell.columns:\n",
    "    cell_num = int(cell_id.split(\"_\")[0].replace(\"cell\",\"\"))\n",
    "    cell_pos = int(cell_id.split(\"_\")[1].replace(\"pos\",\"\"))\n",
    "    get_area = area_smfish[(area_smfish[\"cell number\"] == cell_num)&(area_smfish[\"pos\"] == cell_pos)]\n",
    "    area = get_area.area.iloc[0]\n",
    "    genebycell[cell_id]=(genebycell[cell_id]/area)/(pixel**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = pd.concat(current_df,axis=1).fillna(0)\n",
    "#mtx_ref = pd.concat(old_df,axis=1).fillna(0)\n",
    "mtx_ref = genebycell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(mtx,mtx_ref, label_x=\"smFISH\", label_y=\"LANTERN\",\n",
    "            title=\"4000 gene experiment (061222) Channel 488 nm\", return_comb_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare undefineds\n",
    "percent_und_list = []\n",
    "channel=3\n",
    "for i in range(25):\n",
    "    current_und = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_222_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/dots_used_undefined_z_0.csv\")\n",
    "    current_und = current_und[current_und[\"hyb\"] < 48]\n",
    "    current_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    current_loc = current_loc[current_loc[\"hyb\"] < 48]\n",
    "    current_per = len(current_und)/len(current_loc)\n",
    "    \n",
    "    old_und = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/dots_used_undefined_z_0.csv\")\n",
    "    old_und = old_und[old_und[\"hyb\"] <48]\n",
    "    old_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    old_loc = old_loc[old_loc[\"hyb\"] <48]\n",
    "    old_per = len(old_und)/len(old_loc)\n",
    "    \n",
    "    diff = current_per-old_per\n",
    "    \n",
    "    percent_und_list.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_und_list)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare fakes\n",
    "percent_fake_list = []\n",
    "channel=3\n",
    "for i in range(25):\n",
    "    current_fake = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_222_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/dots_used_fakes_z_0.csv\")\n",
    "    current_fake = current_fake[current_fake[\"hyb\"] < 48]\n",
    "    current_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    current_loc = current_loc[current_loc[\"hyb\"] < 48]\n",
    "    current_per = len(current_fake)/len(current_loc)\n",
    "    \n",
    "    old_fake = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/decoded/final_11p52_33_heg_svm_0p15_diff1_fdr10/Channel_{channel}/Pos_{i}/dots_used_fakes_z_0.csv\")\n",
    "    old_fake = old_fake[old_fake[\"hyb\"] <48]\n",
    "    old_loc = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/06122022_4kgenes/notebook_pyfiles/dots_detected/Channel_{channel}/genes_in_cells/Pos{i}/locations_z_0.csv\")\n",
    "    old_loc = old_loc[old_loc[\"hyb\"] <48]\n",
    "    old_per = len(old_fake)/len(old_loc)\n",
    "    \n",
    "    diff = current_per-old_per\n",
    "    \n",
    "    percent_fake_list.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(percent_fake_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify problematic hybs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse into gene counts\n",
    "counts_df = Counter(fake[\"genes\"])\n",
    "#change to df\n",
    "counts_df = pd.DataFrame.from_dict(counts_df, orient='index').reset_index()\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check codebook\n",
    "codebook = pd.read_csv(\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/barcode_key/codebook_647nm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase gene names\n",
    "codebook.index = codebook.index.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top 30\n",
    "maj_fakes = counts_df.sort_values(0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get troubled hybs\n",
    "troubled_hybs = []\n",
    "for fakes in maj_fakes[\"index\"]:\n",
    "    troubled_hybs.append(codebook.loc[fakes].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "hybstocheck = np.array(troubled_hybs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "hybstocheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mode for each round\n",
    "bad_hybs = []\n",
    "for i in range(len(hybstocheck[0])):\n",
    "    vals,counts = np.unique(hybstocheck[:,i], return_counts=True)\n",
    "    index = np.argmax(counts)\n",
    "    bad_hyb = vals[index]\n",
    "    bad_hybs.append(bad_hyb)\n",
    "\n",
    "print(f\"Following hybs by rounds are problematic:{bad_hybs}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
