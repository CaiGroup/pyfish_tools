{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "#plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#custom function\n",
    "from false_positive_analysis import percent_false_positive\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in final mtx\n",
    "#grab all channels\n",
    "all_channels = []\n",
    "\n",
    "for c in [1]:\n",
    "    mtx = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/notebook_pyfiles/genebycell/final_thresh7_11p52_33_heg_filt/final/genebycell_{c}.csv\", index_col=0)\n",
    "    mtx = mtx.T\n",
    "    mtx = mtx[mtx.sum(axis=1)>100].T\n",
    "    mtx = mtx[mtx.sum(axis=1)>1]\n",
    "    all_channels.append(mtx)\n",
    "\n",
    "mtx = pd.concat(all_channels, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in rnaseq data\n",
    "rnaseq = pd.read_csv(\"./RNAseq_files/nih3t3_FPKM_CCS.csv\")\n",
    "rnaseq.columns = [\"Genes\",\"FPKM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codebook\n",
    "codebook = pd.read_csv(\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/barcode_key/convert_barcode_key/codebook_string_561.csv\", index_col=0)\n",
    "#separate into true and false codebook\n",
    "fakebook = codebook[codebook.index.str.startswith(\"fake\")]\n",
    "codebook = codebook.drop(fakebook.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate fdr\n",
    "fp, fake, norm_fpr= percent_false_positive(mtx, codebook, fakebook)\n",
    "percent_fp = fp[\"FP raw\"].mean()\n",
    "mean_counts = fp[\"total_counts\"].mean()\n",
    "sum_counts = fp[\"total_counts\"].sum()\n",
    "fp_list = [percent_fp,norm_fpr,mean_counts,sum_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at fdr results\n",
    "df_stats = pd.DataFrame(fp_list).T\n",
    "df_stats.columns = [\"percent fp\",\"false positive rate\",\"mean counts\", \"total sum\"]\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "rnaseq[\"Genes\"] = rnaseq[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_1 = pd.merge(rnaseq,bulk)\n",
    "#pearson's correlation\n",
    "r = pearsonr(comb_1[\"FPKM\"],comb_1[\"Counts\"])\n",
    "r = round(r[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get log2 + 1\n",
    "comb_1[\"Log Counts\"] = np.log2(comb_1[\"Counts\"]+1)\n",
    "comb_1[\"Log FPKM\"] = np.log2(comb_1[\"FPKM\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rnaseq correlations\n",
    "plt.plot(comb_1[\"Log Counts\"], comb_1[\"Log FPKM\"], 'bo', alpha=0.5)\n",
    "plt.title(\"Channel 647 nm\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Bulk RNAseq Log2(FPKM+1)\", fontsize=12)\n",
    "plt.xlabel(\"Pseudobulk Log2(Counts+1)\", fontsize=12)\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (0.5,10), fontsize=12)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in smfish \n",
    "smfish = pd.read_csv(\"./smFISH_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pseudobulk results \n",
    "smfish_df = pd.DataFrame(smfish.T.mean(axis=1))\n",
    "smfish_df = smfish_df.reset_index()\n",
    "smfish_df.columns = [\"Genes\", \"smFISH Counts\"]\n",
    "smfish_df[\"Genes\"] = smfish_df[\"Genes\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to pseudobulk rnaseq data\n",
    "bulk = pd.DataFrame(mtx.mean(axis=1)).reset_index()\n",
    "bulk.columns = [\"Genes\", \"Counts\"]\n",
    "bulk[\"Genes\"] = bulk[\"Genes\"].str.lower()\n",
    "#merge\n",
    "comb_2 = pd.merge(smfish_df,bulk)\n",
    "#calculate info\n",
    "x = comb_2[\"smFISH Counts\"].values\n",
    "x_t = np.vstack([x, np.zeros(len(x))]).T\n",
    "y = comb_2[\"Counts\"].values\n",
    "m,c = np.linalg.lstsq(x_t, y, rcond=None)[0]\n",
    "r = pearsonr(x,y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show smfish correlation\n",
    "plt.plot(x, y, 'bo', alpha=0.5)\n",
    "plt.plot(x, x*m, c = \"k\")\n",
    "plt.title(\"Channel 647 nm\", fontweight=\"bold\")\n",
    "plt.xlabel(\"Average smFISH counts\")\n",
    "plt.ylabel(\"Average LANTERN Counts\")\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (0,230), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (0,210), fontsize=12)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation and efficiency\n",
    "plt.scatter(x = np.log2(comb_2[\"smFISH Counts\"]), y = np.log2(comb_2[\"Counts\"]), c=\"b\", alpha=0.5)\n",
    "plt.xlabel(\"Log2(Average smFISH Counts)\", fontsize=12)\n",
    "plt.ylabel(\"Log2(Average LANTERN Counts)\", fontsize=12)\n",
    "plt.annotate(f\"Pearson's r= {round(r,2)}\", (-1,8), fontsize=12)\n",
    "plt.annotate(f\"Efficiency = {round(m,2)}\", (-1,7.3), fontsize=12)\n",
    "plt.title(\"Channel 647 nm\", fontweight=\"bold\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off target properties for potential filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in one of the gene mapped locations file\n",
    "locations = pd.read_csv(f\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/notebook_pyfiles/decoded/final_thresh8_11p52_33_heg/Channel_1/genes_in_cells/Pos_0/gene_locations.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate trues and fakes\n",
    "fake = locations[locations[\"genes\"].str.startswith(\"fake\")]\n",
    "trues = locations.drop(fake.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histograms of ambiguity score\n",
    "_max=max(np.max(fake[\"ambiguity score\"]),np.max(trues[\"ambiguity score\"]))\n",
    "_min=min(np.min(fake[\"ambiguity score\"]),np.min(trues[\"ambiguity score\"]))\n",
    "\n",
    "plt.hist(trues[\"ambiguity score\"], bins=20, alpha= 0.5, range = (_min,_max), label = \"On\")\n",
    "plt.hist(fake[\"ambiguity score\"], bins=20, color= \"red\", alpha=0.5, range = (_min,_max), label = \"Off\")\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel(\"ambiguity score\")\n",
    "plt.ylabel(\"Counts\")\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histograms of brightness\n",
    "_max=max(np.max(fake[\"brightness\"]),np.max(trues[\"brightness\"]))\n",
    "_min=min(np.min(fake[\"brightness\"]),np.min(trues[\"brightness\"]))\n",
    "\n",
    "plt.hist(trues[\"brightness\"], bins=50, alpha= 0.5, range = (_min,_max), label = \"On\")\n",
    "plt.hist(fake[\"brightness\"], bins=50, color= \"red\", alpha=0.5, range = (_min,_max), label = \"Off\")\n",
    "#plt.xlim(0,10)\n",
    "plt.xlabel(\"Flux\")\n",
    "plt.ylabel(\"Counts\")\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram of sizes\n",
    "_max=max(np.max(fake[\"size\"]),np.max(trues[\"size\"]))\n",
    "_min=min(np.min(fake[\"size\"]),np.min(trues[\"size\"]))\n",
    "\n",
    "plt.hist(trues[\"size\"], bins=30, alpha= 0.5, range = (_min,_max), label = \"On\")\n",
    "plt.hist(fake[\"size\"], bins=30, color= \"red\", alpha=0.5, range = (_min,_max), label = \"Off\")\n",
    "#plt.xlim(0,10)\n",
    "plt.xlabel(\"Size\")\n",
    "plt.ylabel(\"Counts\")\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot size and brightness\n",
    "plt.scatter(trues[\"brightness\"],trues[\"size\"], label = \"On\",c=\"blue\", alpha=0.5)\n",
    "plt.scatter(fake[\"brightness\"],fake[\"size\"], label = \"Off\",c=\"red\", alpha=0.5)\n",
    "#plt.xlim(0,10)\n",
    "plt.xlabel(\"Flux\")\n",
    "plt.ylabel(\"Size\")\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter\n",
    "plt.scatter(trues[trues[\"brightness\"]>2.5][\"brightness\"],trues[trues[\"brightness\"]>2.5][\"size\"], label = \"On\",c=\"blue\", alpha=0.5)\n",
    "plt.scatter(fake[fake[\"brightness\"]>2.5][\"brightness\"],fake[fake[\"brightness\"]>2.5][\"size\"], label = \"Off\",c=\"red\", alpha=0.5)\n",
    "plt.scatter(trues[trues[\"brightness\"]<2.5][\"brightness\"],trues[trues[\"brightness\"]<2.5][\"size\"],c=\"gray\",  alpha=0.5)\n",
    "plt.scatter(fake[fake[\"brightness\"]<2.5][\"brightness\"],fake[fake[\"brightness\"]<2.5][\"size\"],c=\"gray\", alpha=0.5)\n",
    "#plt.xlim(0,10)\n",
    "plt.xlabel(\"Flux\")\n",
    "plt.ylabel(\"Size\")\n",
    "plt.axvline(2.5, c = \"black\")\n",
    "sns.despine()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out filtered gene locations\n",
    "from pathlib import Path\n",
    "ch=1\n",
    "pos_list = np.arange(0,40,1)\n",
    "for pos in pos_list:\n",
    "    path = Path(f\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/notebook_pyfiles/decoded/final_thresh7_11p52_33_heg/Channel_1/genes_in_cells/Pos_{pos}/gene_locations.csv\")\n",
    "    locations = pd.read_csv(str(path), index_col=0)\n",
    "    locations=locations[locations[\"brightness\"]>2.5]\n",
    "    output_path = path.parent /\"gene_locations_filt.csv\"\n",
    "    locations.to_csv(str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify problematic hybs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse into gene counts\n",
    "counts_df = Counter(fake[\"genes\"])\n",
    "#change to df\n",
    "counts_df = pd.DataFrame.from_dict(counts_df, orient='index').reset_index()\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check codebook\n",
    "codebook = pd.read_csv(\"/groups/CaiLab/personal/Lex/raw/150genes3bind_040622/barcode_key/codebook_647nm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase gene names\n",
    "codebook.index = codebook.index.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top 30\n",
    "maj_fakes = counts_df.sort_values(0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get troubled hybs\n",
    "troubled_hybs = []\n",
    "for fakes in maj_fakes[\"index\"]:\n",
    "    troubled_hybs.append(codebook.loc[fakes].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "hybstocheck = np.array(troubled_hybs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "hybstocheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mode for each round\n",
    "bad_hybs = []\n",
    "for i in range(len(hybstocheck[0])):\n",
    "    vals,counts = np.unique(hybstocheck[:,i], return_counts=True)\n",
    "    index = np.argmax(counts)\n",
    "    bad_hyb = vals[index]\n",
    "    bad_hybs.append(bad_hyb)\n",
    "\n",
    "print(f\"Following hybs by rounds are problematic:{bad_hybs}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cai Lab common)",
   "language": "python",
   "name": "python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
